{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8b5eac",
   "metadata": {},
   "source": [
    "1) Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "7c7a096c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amazon Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Amazon Review  Sentiment\n",
       "0  So there is no way for me to plug it in here i...          0\n",
       "1                        Good case, Excellent value.          1\n",
       "2                             Great for the jawbone.          1\n",
       "3  Tied to charger for conversations lasting more...          0\n",
       "4                                  The mic is great.          1"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "data = pd.read_csv(r\"C:\\Users\\yuras\\OneDrive\\Документы\\ML_ASSIGNMENT\\archive\\sentiment labelled sentences\\sentiment labelled sentences\\amazon_cells_labelled.txt\",\n",
    "                 delimiter=\"\\t\",header=None,names=[\"Amazon Review\",\"Sentiment\"])\n",
    "\n",
    "data_test = pd.read_csv(r\"C:\\Users\\yuras\\OneDrive\\Документы\\ML_ASSIGNMENT\\archive\\sentiment labelled sentences\\sentiment labelled sentences\\amazon_cells_labelled.txt\",\n",
    "                 delimiter=\"\\t\",header=None,names=[\"Amazon Review\",\"Sentiment\"])\n",
    "\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5021112",
   "metadata": {},
   "source": [
    "2) Applying CountVectorizer, and then TfidTransformer to the dataset.\n",
    "3) Predicting the data using Naive Bayes classifier and testing the accuracy of the prediction\n",
    "\n",
    "CountVectorizer - Converts a collection of text documents to a matrix of token counts. \n",
    "\n",
    "TfidTransformer - for applying Term Frequencies and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "8f8bfa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1847)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.964"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(data[\"Amazon Review\"])\n",
    "\n",
    "#print(X_train_counts)\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "#print(X_train_tfidf)\n",
    "\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, data[\"Sentiment\"])\n",
    "predict = clf.predict(X_train_tfidf)\n",
    "np.mean(predict == data[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ebde0e",
   "metadata": {},
   "source": [
    "4) The same process as before but using a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "44b9a07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),                    \n",
    "                     ('clf', MultinomialNB()), ])\n",
    "\n",
    "text_clf = text_clf.fit(data_test[\"Amazon Review\"], data_test[\"Sentiment\"])\n",
    "\n",
    "predicted = text_clf.predict(data_test[\"Amazon Review\"])\n",
    "np.mean(predicted == data_test[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573c688",
   "metadata": {},
   "source": [
    "5) Performing data preprocessing\n",
    "\n",
    "Step 1 - removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "5bdc8d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amazon Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case Excellent value</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Amazon Review  Sentiment\n",
       "0  So there is no way for me to plug it in here i...          0\n",
       "1                          Good case Excellent value          1\n",
       "2                              Great for the jawbone          1\n",
       "3  Tied to charger for conversations lasting more...          0\n",
       "4                                   The mic is great          1"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contraction_dict = {\"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\"}\n",
    "string.punctuation\n",
    "new_data = pd.read_csv(r\"C:\\Users\\yuras\\OneDrive\\Документы\\ML_ASSIGNMENT\\archive\\sentiment labelled sentences\\sentiment labelled sentences\\amazon_cells_labelled.txt\",\n",
    "                 delimiter=\"\\t\",header=None,names=[\"Amazon Review\",\"Sentiment\"])\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "new_data[\"Amazon Review\"]= new_data[\"Amazon Review\"].apply(lambda x:remove_punctuation(x))\n",
    "\n",
    "new_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea1eaf5",
   "metadata": {},
   "source": [
    "Step 2 - lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "cacaa207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amazon Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case excellent value</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great for the jawbone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the mic is great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Amazon Review  Sentiment\n",
       "0  so there is no way for me to plug it in here i...          0\n",
       "1                          good case excellent value          1\n",
       "2                              great for the jawbone          1\n",
       "3  tied to charger for conversations lasting more...          0\n",
       "4                                   the mic is great          1"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[\"Amazon Review\"] = new_data[\"Amazon Review\"].apply(lambda x: x.lower())\n",
    "new_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9446cd65",
   "metadata": {},
   "source": [
    "Step 3 - tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "e6e9bd9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amazon Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[so, there, is, no, way, for, me, to, plug, it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Amazon Review  Sentiment\n",
       "0  [so, there, is, no, way, for, me, to, plug, it...          0\n",
       "1                     [good, case, excellent, value]          1\n",
       "2                         [great, for, the, jawbone]          1\n",
       "3  [tied, to, charger, for, conversations, lastin...          0\n",
       "4                              [the, mic, is, great]          1"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenization(text):\n",
    "    text = str(text)\n",
    "    tokens = re.split('W+',text)\n",
    "    return tokens\n",
    "new_data[\"Amazon Review\"] = new_data.apply(lambda row: nltk.word_tokenize(row[\"Amazon Review\"]), axis=1)\n",
    "new_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafce73c",
   "metadata": {},
   "source": [
    "Step 4 - stop words removal (Such as i, me, you..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "87eb8ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amazon Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[way, plug, us, unless, go, converter]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[tied, charger, conversations, lasting, 45, mi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mic, great]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[jiggle, plug, get, line, right, get, decent, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[several, dozen, several, hundred, contacts, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[razr, owneryou, must]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[needless, say, wasted, money]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[waste, money, time]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Amazon Review  Sentiment\n",
       "0             [way, plug, us, unless, go, converter]          0\n",
       "1                     [good, case, excellent, value]          1\n",
       "2                                   [great, jawbone]          1\n",
       "3  [tied, charger, conversations, lasting, 45, mi...          0\n",
       "4                                       [mic, great]          1\n",
       "5  [jiggle, plug, get, line, right, get, decent, ...          0\n",
       "6  [several, dozen, several, hundred, contacts, i...          0\n",
       "7                             [razr, owneryou, must]          1\n",
       "8                     [needless, say, wasted, money]          0\n",
       "9                               [waste, money, time]          0"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "#print(stopwords)\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "new_data[\"Amazon Review\"] = new_data[\"Amazon Review\"].apply(lambda x:remove_stopwords(x))\n",
    "new_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca06d8f",
   "metadata": {},
   "source": [
    "Step 5 - Lemmanization (Recover words after stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "adaf31e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amazon Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[way, plug, u, unless, go, converter]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[tied, charger, conversation, lasting, 45, min...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mic, great]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Amazon Review  Sentiment\n",
       "0              [way, plug, u, unless, go, converter]          0\n",
       "1                     [good, case, excellent, value]          1\n",
       "2                                   [great, jawbone]          1\n",
       "3  [tied, charger, conversation, lasting, 45, min...          0\n",
       "4                                       [mic, great]          1"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text\n",
    "new_data[\"Amazon Review\"] = new_data[\"Amazon Review\"].apply(lambda x:lemmatizer(x))\n",
    "new_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce57a57",
   "metadata": {},
   "source": [
    "I have run into problems trying to classify the data after tokenization. \n",
    "\n",
    "Below is another version of data preprocessing implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "6cb5ca93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amazon Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Amazon Review  Sentiment\n",
       "0  So there is no way for me to plug it in here i...          0\n",
       "1                        Good case, Excellent value.          1\n",
       "2                             Great for the jawbone.          1\n",
       "3  Tied to charger for conversations lasting more...          0\n",
       "4                                  The mic is great.          1"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize_words(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "def preprocess_data(new_data, f1, f2):\n",
    "    #Step 1 - contraction\n",
    "    contraction_dict = {\"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\"}\n",
    "    #Step 2 - punctuation\n",
    "    string.punctuation\n",
    "    new_data[f1] = new_data[f1].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))\n",
    "    #Step 3 - lowercasing \n",
    "    new_data[f1] = new_data[f1].apply(lambda x: x.lower())\n",
    "    #Step 4 - remove digits\n",
    "    new_data[f1] = new_data[f1].apply(lambda x: re.sub('W*dw*','',x))\n",
    "    #Step 5 - lemmanization \n",
    "    new_data[f1] = new_data[f1].apply(lambda text: lemmatize_words(text))\n",
    "    \n",
    "    \n",
    "    return new_data\n",
    "amazon_data = pd.read_csv(r\"C:\\Users\\yuras\\OneDrive\\Документы\\ML_ASSIGNMENT\\archive\\sentiment labelled sentences\\sentiment labelled sentences\\amazon_cells_labelled.txt\",\n",
    "                 delimiter=\"\\t\",header=None,names=[\"Amazon Review\",\"Sentiment\"])\n",
    "amazon_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf485be2",
   "metadata": {},
   "source": [
    "Now we can compare the initial input and the result after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "f88ab157",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),                    \n",
    "                     ('clf', MultinomialNB()), ])\n",
    "\n",
    "amazon_data = preprocess_data(amazon_data, \"Amazon Review\", \"Sentiment\")\n",
    "\n",
    "text_clf = text_clf.fit(amazon_data[\"Amazon Review\"], amazon_data[\"Sentiment\"])\n",
    "\n",
    "predicted = text_clf.predict(amazon_data[\"Amazon Review\"])\n",
    "np.mean(predicted == amazon_data[\"Sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bc9770",
   "metadata": {},
   "source": [
    "Now, let's repeat the process for the rest of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "7ee8abb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9812834224598931"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data = pd.read_csv(r\"C:\\Users\\yuras\\OneDrive\\Документы\\ML_ASSIGNMENT\\archive\\sentiment labelled sentences\\imdb_labelled.txt\",\n",
    "                 delimiter=\"\\t\",header=None,names=[\"Imdb Review\",\"Sentiment\"])\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),                    \n",
    "                     ('clf', MultinomialNB()), ])\n",
    "\n",
    "text_clf = text_clf.fit(imdb_data[\"Imdb Review\"], imdb_data[\"Sentiment\"])\n",
    "\n",
    "predicted = text_clf.predict(imdb_data[\"Imdb Review\"])\n",
    "np.mean(predicted == imdb_data[\"Sentiment\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5d3ad",
   "metadata": {},
   "source": [
    "What value to expect using preprocessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d7644acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9786096256684492"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data = preprocess_data(imdb_data, \"Imdb Review\", \"Sentiment\")\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),                    \n",
    "                     ('clf', MultinomialNB()), ])\n",
    "\n",
    "text_clf = text_clf.fit(imdb_data[\"Imdb Review\"], imdb_data[\"Sentiment\"])\n",
    "\n",
    "predicted = text_clf.predict(imdb_data[\"Imdb Review\"])\n",
    "np.mean(predicted == imdb_data[\"Sentiment\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b4b35a",
   "metadata": {},
   "source": [
    "The same process for yelp reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "501d4af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_data = pd.read_csv(r\"C:\\Users\\yuras\\OneDrive\\Документы\\ML_ASSIGNMENT\\archive\\sentiment labelled sentences\\yelp_labelled.txt\",\n",
    "                 delimiter=\"\\t\",header=None,names=[\"Yelp Review\",\"Sentiment\"])\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),                    \n",
    "                     ('clf', MultinomialNB()), ])\n",
    "\n",
    "text_clf = text_clf.fit(yelp_data[\"Yelp Review\"], yelp_data[\"Sentiment\"])\n",
    "\n",
    "predicted = text_clf.predict(yelp_data[\"Yelp Review\"])\n",
    "np.mean(predicted == yelp_data[\"Sentiment\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "8da80f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.962"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_data = preprocess_data(yelp_data, \"Yelp Review\", \"Sentiment\")\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                      ('tfidf', TfidfTransformer()),                    \n",
    "                     ('clf', MultinomialNB()), ])\n",
    "\n",
    "text_clf = text_clf.fit(yelp_data[\"Yelp Review\"], yelp_data[\"Sentiment\"])\n",
    "\n",
    "predicted = text_clf.predict(yelp_data[\"Yelp Review\"])\n",
    "np.mean(predicted == yelp_data[\"Sentiment\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3652d2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
